{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 워드임베딩 : Word를 vector로 바꾸는 것\n",
    "- word2vec : word를 vector 바꾸는 모델 (예: CNN, GAN 등과 같은 방식을 의미)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAXC16IcTRfp",
    "outputId": "5e91094d-92b1-4818-e8ab-1fd93a0cd8f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# COLAB에서만 동작하는 코드\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTgtpfC4eHuP"
   },
   "source": [
    "# 텍스트 분류\n",
    "\n",
    "copied and modified from https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WERUuDeQCLq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:13.363135Z",
     "start_time": "2021-08-01T16:22:13.354159Z"
    },
    "id": "KVZ8aq96QC0Y"
   },
   "outputs": [],
   "source": [
    "## 설정\n",
    "VOCA_SIZE = 4000 # 어휘 사전의 크기\n",
    "EMBEDDING_SIZE = 64 # 단어를 임베딩한 벡터 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xeAkpUYJPpy"
   },
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:22.606905Z",
     "start_time": "2021-08-01T16:22:16.230865Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nglK_9Hd3_r",
    "outputId": "d70df813-c6a1-4169-d581-bc1490db5d0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\JuNoe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuNoe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('Loading data...')\n",
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.imdb.load_data(num_words=VOCA_SIZE)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imdb는 긍정/부정 리뷰 데이터\n",
    "- imdb에서 가져올 단어로 voca_size를 설정하면 설정된 단어만큼 숫자로 변환해서 가져옴\n",
    "- (25000,)의 의미는 25000개의 리뷰데이터와 데이터 하나당 길이를 알 수 없다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2B3TWo3_JR2U"
   },
   "source": [
    "## 데이터 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:25.474803Z",
     "start_time": "2021-08-01T16:22:25.467822Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 2, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:27.584324Z",
     "start_time": "2021-08-01T16:22:27.564377Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:28.062910Z",
     "start_time": "2021-08-01T16:22:28.047951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:28.797360Z",
     "start_time": "2021-08-01T16:22:28.793371Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTUxzKwFJigM",
    "outputId": "0c85e366-0904-4620-8b46-941d15f4eb3a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 2, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 2, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 2, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 2, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
      " list([1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 2, 452, 2, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 2, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 2, 4, 1615, 5, 2, 7, 2, 17, 13, 2, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 2, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 2, 5, 27, 2, 159, 90, 263, 2311, 2, 309, 8, 178, 5, 82, 2, 4, 65, 15, 2, 145, 143, 2, 12, 2, 537, 746, 537, 537, 15, 2, 4, 2, 594, 7, 2, 94, 2, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 2, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 2, 27, 2, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 2, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 2, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 2, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 2, 132, 8, 67, 6, 22, 15, 9, 283, 8, 2, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 2, 15, 566, 30, 579, 21, 64, 2574])\n",
      " list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 2, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 2, 6, 226, 251, 7, 61, 113])]\n",
      "[1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[:5])\n",
    "print(train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:31.610863Z",
     "start_time": "2021-08-01T16:22:31.241850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifl7K71wNchw"
   },
   "source": [
    "## 텍스트로 데이터 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:36.207007Z",
     "start_time": "2021-08-01T16:22:36.111263Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkw9MdgJLZOX",
    "outputId": "d7b60d07-0c93-4ffc-ee18-7ed4c3006c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 2, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "<START> this film was just brilliant casting location scenery story direction <UNK> really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> island as myself so i loved the fact there was a real connection with this film the witty <UNK> throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly <UNK> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so lovely because it was true and was <UNK> life after all that was <UNK> with us all\n"
     ]
    }
   ],
   "source": [
    "# 단어와 정수 인덱스를 매핑한 딕셔너리\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "# word_index = {'fawn': 34701, 'tsukino': 52006, 'nunnery': 52007, ... }\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "# imdb.get_word_index()에 저장된 값에 +3을 해야 실제 맵핑되는 정수\n",
    "# 이것은 IMDB 리뷰 데이터셋에서 정한 규칙\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# word_index에서 key와 value를 바꿔놓는 코드\n",
    "# dictionary 만들기 보충자료 참고\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# reverse_word_index = {34704: 'fawn', 52009: 'tsukino', 52010: 'nunnery', ... }\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text]) # get함수 보충자료 참고 \n",
    "#>>> ','.join('abcd')\n",
    "# 'a,b,c,d'\n",
    "print(train_x[0])\n",
    "print(decode_review(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Oxp3l0TJzgq"
   },
   "source": [
    "## 각 데이터의 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:38.596533Z",
     "start_time": "2021-08-01T16:22:38.586560Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sx0jFfDqHh4q",
    "outputId": "6a3f350c-28a3-4acf-e5f1-29f1cdb58515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n",
      "141\n",
      "550\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x[0]))\n",
    "print(len(train_x[1]))\n",
    "print(len(train_x[2]))\n",
    "print(len(train_x[3]))\n",
    "print(len(train_x[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICmUFp5tNmGp"
   },
   "source": [
    "## 데이터 길이 일정하게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:40.440470Z",
     "start_time": "2021-08-01T16:22:40.432494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpkgDH3CO4gG",
    "outputId": "466666bd-1cfc-4a62-ac4e-9bdcd220c8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 2, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(len(train_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:46.389436Z",
     "start_time": "2021-08-01T16:22:45.600230Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C6fLRb_HA8A",
    "outputId": "b4bec9e1-9add-45df-ca1b-381719f65163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 400)\n",
      "(25000, 400)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# 길이를 400으로 padding은 뒤로\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=400, padding='post')\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=400, padding='post')\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:22:54.208024Z",
     "start_time": "2021-08-01T16:22:54.190106Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6gb4O2OeWcO",
    "outputId": "6c427811-d062-45f3-973e-d18a8a370287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458    2   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172    2 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920    2  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      "    2   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117    2   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194    2   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30    2   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16    2  113\n",
      "  103   32   15   16    2   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(len(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yoibr3xQN0Vq"
   },
   "source": [
    "## CNN 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:24:29.386370Z",
     "start_time": "2021-08-01T16:22:57.572644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYlvpK2neGdv",
    "outputId": "18cec54d-9382-4f30-ca11-2285aafa892f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 64)           256000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 250)          48250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 367,251\n",
      "Trainable params: 367,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 11s 12ms/step - loss: 0.3965 - accuracy: 0.8046 - val_loss: 0.2773 - val_accuracy: 0.8840\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2247 - accuracy: 0.9088 - val_loss: 0.2694 - val_accuracy: 0.8916\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1556 - accuracy: 0.9410 - val_loss: 0.2722 - val_accuracy: 0.8925\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1053 - accuracy: 0.9629 - val_loss: 0.3062 - val_accuracy: 0.8886\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0696 - accuracy: 0.9766 - val_loss: 0.3673 - val_accuracy: 0.8891\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0553 - accuracy: 0.9795 - val_loss: 0.4157 - val_accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0410 - accuracy: 0.9848 - val_loss: 0.4741 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0372 - accuracy: 0.9870 - val_loss: 0.5004 - val_accuracy: 0.8811\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.4693 - val_accuracy: 0.8883\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.4691 - val_accuracy: 0.8861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2344e990d60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(400))\n",
    "model.add(Embedding(VOCA_SIZE, EMBEDDING_SIZE)) # 텍스트는 임베딩 해서 사용한다.\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250, 3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=10, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:24:45.743727Z",
     "start_time": "2021-08-01T16:24:43.024554Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28CiZH01d5RR",
    "outputId": "7ac40096-684f-4130-920a-3f7a7948a713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4691 - accuracy: 0.8861\n",
      "loss = 0.46907028555870056\n",
      "acc = 0.8861200213432312\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss =\", loss)\n",
    "print(\"acc =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQnEiGI_Y-2o"
   },
   "source": [
    "## RNN 모델 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:29:45.790063Z",
     "start_time": "2021-08-01T16:24:47.399983Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKWcjknZZAiF",
    "outputId": "c1c04343-a35b-44f4-a73c-f9aaf365078b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 64)           256000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               32250     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 354,549\n",
      "Trainable params: 354,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 33s 39ms/step - loss: 0.5021 - accuracy: 0.7592 - val_loss: 0.4101 - val_accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 31s 39ms/step - loss: 0.3457 - accuracy: 0.8636 - val_loss: 0.3375 - val_accuracy: 0.8652\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.2826 - accuracy: 0.8907 - val_loss: 0.3215 - val_accuracy: 0.8704\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.2671 - accuracy: 0.8971 - val_loss: 0.5973 - val_accuracy: 0.6219\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.2680 - accuracy: 0.8966 - val_loss: 0.3583 - val_accuracy: 0.8655\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.2053 - accuracy: 0.9250 - val_loss: 0.3445 - val_accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.1841 - accuracy: 0.9331 - val_loss: 0.4241 - val_accuracy: 0.8410\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.1742 - accuracy: 0.9378 - val_loss: 0.4007 - val_accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.1624 - accuracy: 0.9432 - val_loss: 0.4367 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.1610 - accuracy: 0.9448 - val_loss: 0.3958 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2345fc26940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "# from tensorflow.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(400))\n",
    "model.add(Embedding(VOCA_SIZE, EMBEDDING_SIZE)) # 자연어처리 위해 넣은 코드\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Bidirectional(CuDNNLSTM(64))) # COLAB RNN 코드\n",
    "model.add(Bidirectional(LSTM(64))) # 윈도우 RNN 코드 CuDNNLSTM은 내장되있음\n",
    "# https://ws-choi.github.io/blog-kor/nlp/deeplearning/Bidirectional-RNN-and-LSTM/\n",
    "# https://ws-choi.github.io/blog-kor/bidirectional-rnn-in-pytorch/\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=10, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:29:57.598058Z",
     "start_time": "2021-08-01T16:29:48.796781Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nd53lZYFZY0U",
    "outputId": "3e5ae600-a813-4320-849b-deded9a36085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.3958 - accuracy: 0.8683\n",
      "loss = 0.39583566784858704\n",
      "acc = 0.8682799935340881\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss =\", loss)\n",
    "print(\"acc =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQyQSM1UVCh7"
   },
   "source": [
    "# Word2Vec 사용\n",
    "\n",
    "새로 Embedding을 학습하지 않고 이미 학습된 Word2Vec을 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrFo9E4cYDmR",
    "outputId": "de756c69-b69e-4ce5-e92e-39f46ed5b5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKDrAvegcSAN"
   },
   "source": [
    "아래 코드로 로딩이 가능한데, 데이터가 엄청 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T75NMTTjZYm9"
   },
   "outputs": [],
   "source": [
    "# import gensim.downloader as api\n",
    "# word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TUWPXMEcVZF"
   },
   "source": [
    "대신 슬림한 것을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNTK-z2tbsK9",
    "outputId": "4640cd07-d706-49a3-a204-17e604873dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-28 06:00:54--  https://github.com/eyaler/word2vec-slim/raw/master/GoogleNews-vectors-negative300-SLIM.bin.gz\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://media.githubusercontent.com/media/eyaler/word2vec-slim/master/GoogleNews-vectors-negative300-SLIM.bin.gz [following]\n",
      "--2020-11-28 06:00:54--  https://media.githubusercontent.com/media/eyaler/word2vec-slim/master/GoogleNews-vectors-negative300-SLIM.bin.gz\n",
      "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 276467217 (264M) [application/octet-stream]\n",
      "Saving to: ‘GoogleNews-vectors-negative300-SLIM.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>] 263.66M   197MB/s    in 1.3s    \n",
      "\n",
      "2020-11-28 06:01:01 (197 MB/s) - ‘GoogleNews-vectors-negative300-SLIM.bin.gz’ saved [276467217/276467217]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/eyaler/word2vec-slim/raw/master/GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_PRDWT5b9fi"
   },
   "outputs": [],
   "source": [
    "!gzip -d GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:06.500689Z",
     "start_time": "2021-08-01T16:30:03.803701Z"
    },
    "id": "8JtCskE5bzYM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JuNoe\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# \n",
    "word2vec = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300-SLIM.bin\", binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:08.434286Z",
     "start_time": "2021-08-01T16:30:08.412316Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWIBrUKmciet",
    "outputId": "716ca9be-e477-48f9-c725-8a6a564dc1d6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.95743926e-02  5.22915944e-02 -5.08934222e-02  4.75378111e-02\n",
      "  4.19451296e-02  7.27048889e-03  1.43312523e-02 -1.00668306e-02\n",
      "  7.27048889e-02  6.37915509e-04 -9.33934498e-05 -5.87231815e-02\n",
      " -8.55680630e-02 -1.06260993e-01 -1.27513185e-01 -5.95620833e-02\n",
      " -5.42490333e-02 -1.63848163e-04 -7.01881796e-02 -5.98417185e-02\n",
      "  7.21456185e-02 -1.06820263e-01  5.48083000e-02 -5.94222639e-03\n",
      " -8.50087926e-02  3.55135426e-02 -1.31987333e-01  4.08265926e-02\n",
      "  2.04692230e-01  3.39755528e-02 -4.22247648e-02 -3.29968333e-02\n",
      " -2.58661620e-02 -2.43281741e-02 -9.00422111e-02  4.41822037e-02\n",
      " -5.64861074e-02  8.27717185e-02  9.33978185e-02  7.99753815e-02\n",
      " -6.11699792e-03 -2.22309176e-02  3.71913463e-02  5.14526926e-02\n",
      "  8.16531852e-02 -7.01881796e-02 -2.06929296e-02 -3.10393963e-02\n",
      "  1.13531485e-01  7.88568407e-02 -8.44495296e-02  8.22124556e-02\n",
      " -2.67400197e-03 -6.15195222e-02  2.96412241e-02 -3.80302519e-02\n",
      "  5.45286685e-02 -7.27048889e-02  1.09616600e-01  1.02765569e-02\n",
      "  2.88023222e-02  2.99208593e-02  4.72581796e-02 -6.29176944e-02\n",
      "  3.94284204e-02 -5.39693981e-02  2.01336611e-02 -2.57263463e-02\n",
      " -6.20787926e-02 -2.15842645e-03 -2.48874426e-02  1.70576852e-02\n",
      "  2.01336611e-02 -1.68479607e-02 -1.33525329e-02 -1.04163736e-02\n",
      "  3.29968333e-02 -9.73126963e-02 -2.49923067e-03 -5.52714453e-04\n",
      " -5.38295833e-03 -5.45286685e-02  4.69785444e-02  7.27048889e-02\n",
      " -1.00109041e-01 -2.97810417e-02 -2.09725648e-02 -6.01213500e-02\n",
      " -2.25105528e-02 -3.36959213e-02 -1.18844528e-02  1.24157585e-01\n",
      " -1.87354907e-02  1.68479607e-02 -8.55680630e-02 -1.21920511e-01\n",
      "  5.28508611e-02  3.45348231e-02  5.17323241e-02 -7.27048889e-02\n",
      " -2.19512843e-02 -4.41822037e-02 -7.37535162e-03 -4.75378111e-02\n",
      "  6.51547685e-02 -8.44495296e-02 -2.76837852e-02 -3.48144583e-02\n",
      "  3.28570195e-02 -3.88691537e-02 -1.48765385e-01  2.40485407e-02\n",
      "  8.45893472e-03  8.27717185e-02 -5.62064722e-02 -2.47476269e-02\n",
      " -4.13858593e-02 -1.39257833e-01 -7.88568407e-02 -8.38902593e-03\n",
      " -5.55772940e-03  5.56472056e-02 -1.04583189e-01 -3.65272164e-03\n",
      " -4.11062278e-02  1.78965889e-02  1.09616600e-01 -2.41883583e-02\n",
      "  4.30636667e-02 -1.06260993e-01 -4.08265926e-02  3.48144583e-02\n",
      " -9.28385556e-02  4.27840315e-02 -6.48751333e-02  5.36897667e-02\n",
      "  2.62856148e-02  6.81608357e-03  2.60059796e-02  1.69877764e-02\n",
      "  5.36897667e-02 -8.83644074e-02 -2.12521981e-02  1.90151259e-02\n",
      "  1.37719838e-02  8.72458667e-02 -5.00545204e-02  8.10939148e-02\n",
      "  4.31685289e-03 -2.99208593e-02  1.33105874e-01  4.39025685e-02\n",
      " -7.88568407e-02  5.84435463e-02  5.48083000e-02 -7.15863556e-02\n",
      "  3.46047315e-03 -1.01367394e-02  4.19451296e-02 -5.17323241e-02\n",
      "  3.57931778e-02 -5.90028130e-02  6.06806204e-02 -1.69877764e-02\n",
      "  2.48175347e-03 -2.33494546e-02  7.71790370e-02 -7.21456185e-02\n",
      " -7.79480301e-03  3.57931778e-02 -2.65652481e-02 -2.05531139e-02\n",
      "  1.27233556e-02  3.71913463e-02  2.01336611e-02 -2.39087231e-02\n",
      "  1.06260991e-02  2.71245167e-02 -5.73250093e-02 -9.33978185e-02\n",
      " -7.88568407e-02 -6.82307407e-02 -3.50940898e-02 -3.77506167e-02\n",
      "  1.62886921e-02 -6.68325722e-02  2.98859039e-03  5.34101315e-02\n",
      "  6.68325722e-02  1.56595148e-02 -1.92947593e-02 -1.24716848e-01\n",
      " -7.43826926e-02  5.14526926e-02  3.08995787e-02  1.18844528e-02\n",
      "  5.59268380e-03 -7.49419630e-02 -4.19451296e-02  1.71275940e-02\n",
      "  3.66320796e-02 -4.19451296e-02  1.28456962e-03 -4.25043963e-02\n",
      "  3.27172019e-02  6.68500492e-04  1.01227574e-01 -6.51547685e-02\n",
      "  3.22977491e-02 -1.17446361e-02 -1.52121007e-01 -2.08327472e-02\n",
      "  3.94284204e-02 -1.76728815e-01 -3.48144583e-02  8.44495296e-02\n",
      "  1.09057337e-01 -1.11154588e-02  1.71975028e-02  6.73918426e-02\n",
      "  3.80302519e-02  8.17930046e-03 -7.55012333e-02 -3.97080556e-02\n",
      "  4.61396426e-02 -3.07597611e-02 -3.02004926e-02  3.36959213e-02\n",
      "  8.83644074e-02 -1.04862824e-02  2.46078093e-02 -4.27840315e-02\n",
      "  4.66989093e-02  5.43975912e-04 -3.74709815e-02 -3.85895185e-02\n",
      " -1.64285097e-02  2.11123824e-02 -3.17384824e-02 -3.52339074e-02\n",
      "  7.71790370e-02 -8.10939148e-02 -2.41883583e-02 -6.93492815e-02\n",
      "  4.39025685e-02  2.83129630e-03  9.15801991e-03 -5.95620833e-02\n",
      "  8.61273333e-02 -5.31304954e-03 -7.77383074e-02  5.53675704e-02\n",
      " -2.82430537e-02  3.57931778e-02 -4.71882708e-03  1.78965889e-02\n",
      "  2.42932211e-03 -5.17323241e-02 -6.12398870e-02 -4.75378111e-02\n",
      " -7.94161111e-02  3.97080556e-02  1.61069289e-01  1.07659167e-02\n",
      "  6.29176944e-02  6.12398870e-02 -1.39257833e-01 -2.82430537e-02\n",
      " -8.94829445e-03 -5.67657426e-02  8.69487587e-04  1.27233556e-02\n",
      "  1.15349106e-02  1.00668311e-01  7.15863556e-02  2.86625046e-02\n",
      "  5.54899103e-04  1.53798806e-02 -5.84435463e-02  1.45934091e-03\n",
      "  7.55012333e-02 -2.54467111e-02 -5.87231815e-02 -3.07597611e-02\n",
      "  3.66320796e-02 -2.60059796e-02 -3.04801278e-02  3.86244734e-03\n",
      "  8.94829407e-02 -6.64131204e-03 -3.02004926e-02 -1.44710699e-02\n",
      "  4.19451296e-02 -7.51516875e-03  2.58661620e-02  1.13251852e-02\n",
      "  8.42398033e-03  5.45286685e-02 -2.92217731e-02  4.94952537e-02]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec['tiger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:11.511947Z",
     "start_time": "2021-08-01T16:30:11.498990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다차원을 300차원 맵핑\n",
    "len(word2vec['tiger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:12.849822Z",
     "start_time": "2021-08-01T16:30:12.659332Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_0GYR8jcb1g",
    "outputId": "14711b5c-67e3-4af3-b1da-8a27d197d0ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tigers', 0.8028031587600708),\n",
       " ('elephant', 0.6681443452835083),\n",
       " ('rhino', 0.6406095027923584),\n",
       " ('elephants', 0.6400991678237915),\n",
       " ('panther', 0.6312947273254395),\n",
       " ('leopard', 0.6132040619850159),\n",
       " ('tigress', 0.5982028245925903),\n",
       " ('cheetah', 0.5816307663917542),\n",
       " ('lions', 0.5742772817611694),\n",
       " ('gorilla', 0.5742713212966919)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300차원 공간상에서 가장 가까운 단어들\n",
    "word2vec.most_similar('tiger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:23.334045Z",
     "start_time": "2021-08-01T16:30:14.937678Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WovKk-gvWCKK",
    "outputId": "4c3e809e-02f0-4432-a26c-bef44f193e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999\n"
     ]
    }
   ],
   "source": [
    "word_set = set()\n",
    "\n",
    "for i in range(len(train_x)):\n",
    "  words = decode_review(train_x[i]).split(\" \")\n",
    "  word_set.update(words)    # update() 보충자료 참고\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "  words = decode_review(test_x[i]).split(\" \")\n",
    "  word_set.update(words)\n",
    "\n",
    "print(len(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:32:32.610995Z",
     "start_time": "2021-08-01T16:32:32.591049Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selling',\n",
       " 'casting',\n",
       " 'yourself',\n",
       " 'drink',\n",
       " 'currently',\n",
       " 'approach',\n",
       " \"they've\",\n",
       " 'craft',\n",
       " '24',\n",
       " \"children's\",\n",
       " 'hoping',\n",
       " 'considering',\n",
       " 'everything',\n",
       " 'nobody',\n",
       " 'colour',\n",
       " 'traditional',\n",
       " 'found',\n",
       " 'variety',\n",
       " 'ian',\n",
       " 'dad',\n",
       " 'required',\n",
       " 'putting',\n",
       " 'helping',\n",
       " 'innovative',\n",
       " 'edward',\n",
       " 'represents',\n",
       " 'research',\n",
       " 'wars',\n",
       " 'laid',\n",
       " 'wake',\n",
       " 'annie',\n",
       " 'abandoned',\n",
       " 'robot',\n",
       " 'walken',\n",
       " 'broken',\n",
       " 'types',\n",
       " 'anderson',\n",
       " 'avoid',\n",
       " 'jason',\n",
       " 'speed',\n",
       " 'fire',\n",
       " 'shows',\n",
       " 'comment',\n",
       " 'car',\n",
       " 'pulling',\n",
       " 'matthau',\n",
       " 'bollywood',\n",
       " 'racist',\n",
       " 'satire',\n",
       " 'beaten',\n",
       " 'americans',\n",
       " 'u',\n",
       " 'fails',\n",
       " 'viewer',\n",
       " 'ass',\n",
       " 'low',\n",
       " 'bus',\n",
       " 'coherent',\n",
       " 'tiny',\n",
       " 'ghost',\n",
       " 'bar',\n",
       " 'further',\n",
       " 'sequences',\n",
       " 'slowly',\n",
       " \"1950's\",\n",
       " '2',\n",
       " 'jerry',\n",
       " 'space',\n",
       " '6',\n",
       " 'finish',\n",
       " 'butt',\n",
       " 'appropriate',\n",
       " 'hatred',\n",
       " 'fx',\n",
       " 'ben',\n",
       " 'instance',\n",
       " 'memories',\n",
       " 'revealing',\n",
       " 'plague',\n",
       " 'shall',\n",
       " 'mindless',\n",
       " 'touched',\n",
       " \"don't\",\n",
       " 'moves',\n",
       " 'play',\n",
       " 'flynn',\n",
       " 'cop',\n",
       " 'animals',\n",
       " 'finale',\n",
       " 'godfather',\n",
       " 'bodies',\n",
       " 'issues',\n",
       " 'bleak',\n",
       " 'players',\n",
       " 'blank',\n",
       " 'dinner',\n",
       " 'lit',\n",
       " 'grandmother',\n",
       " 'thrills',\n",
       " 'described',\n",
       " 'danger',\n",
       " 'though',\n",
       " 'melodramatic',\n",
       " 'with',\n",
       " 'gripping',\n",
       " 'died',\n",
       " 'hire',\n",
       " 'woody',\n",
       " 'recently',\n",
       " 'might',\n",
       " 'prince',\n",
       " 'compare',\n",
       " 'piano',\n",
       " 'impact',\n",
       " 'child',\n",
       " 'committed',\n",
       " 'knew',\n",
       " 'superhero',\n",
       " 'elements',\n",
       " 'managed',\n",
       " 'emotionally',\n",
       " 'random',\n",
       " 'lacks',\n",
       " 'screenplay',\n",
       " 'lost',\n",
       " 'dramas',\n",
       " 'puts',\n",
       " 'stand',\n",
       " 'everyday',\n",
       " 'then',\n",
       " 'loses',\n",
       " 'sound',\n",
       " 'loud',\n",
       " 'chasing',\n",
       " 'choose',\n",
       " 'china',\n",
       " 'idiot',\n",
       " 'louis',\n",
       " 'visuals',\n",
       " 'overwhelming',\n",
       " 'destroyed',\n",
       " 'single',\n",
       " 'naked',\n",
       " 'able',\n",
       " 'scary',\n",
       " 'son',\n",
       " 'lame',\n",
       " 'incredible',\n",
       " 'bound',\n",
       " 'anything',\n",
       " 'credits',\n",
       " 'somewhat',\n",
       " 'also',\n",
       " 'from',\n",
       " 'parents',\n",
       " 'team',\n",
       " 'attempted',\n",
       " 'hysterical',\n",
       " 'shy',\n",
       " 'bought',\n",
       " 'art',\n",
       " 'hill',\n",
       " 'richard',\n",
       " 'little',\n",
       " 'wing',\n",
       " 'outcome',\n",
       " 'jr',\n",
       " 'red',\n",
       " 'awards',\n",
       " 'four',\n",
       " '\\x96',\n",
       " 'popular',\n",
       " 'piece',\n",
       " 'earlier',\n",
       " 'basic',\n",
       " 'pat',\n",
       " 'cheese',\n",
       " 'boy',\n",
       " 'hang',\n",
       " 'younger',\n",
       " 'stated',\n",
       " 'politics',\n",
       " 'breathtaking',\n",
       " 'pass',\n",
       " 'flicks',\n",
       " 'frankly',\n",
       " 'jet',\n",
       " 'excuse',\n",
       " 'current',\n",
       " 'boring',\n",
       " 'close',\n",
       " 'quirky',\n",
       " 'bettie',\n",
       " 'learn',\n",
       " 'waiting',\n",
       " 'neat',\n",
       " 'york',\n",
       " 'fell',\n",
       " 'quiet',\n",
       " 'weeks',\n",
       " 'narrative',\n",
       " 'cooper',\n",
       " 'ending',\n",
       " 'doubt',\n",
       " 'nazis',\n",
       " 'sophisticated',\n",
       " 'granted',\n",
       " 'riding',\n",
       " 'key',\n",
       " 'practically',\n",
       " 'demands',\n",
       " 'comedy',\n",
       " 'its',\n",
       " 'masterpiece',\n",
       " 'dress',\n",
       " 'spoiler',\n",
       " 'kidnapped',\n",
       " 'count',\n",
       " 'andrew',\n",
       " 'does',\n",
       " 'ryan',\n",
       " 'ii',\n",
       " 'critics',\n",
       " 'lily',\n",
       " 'discovered',\n",
       " 'spy',\n",
       " 'guns',\n",
       " 'hand',\n",
       " 'weak',\n",
       " 'steps',\n",
       " 'called',\n",
       " 'turkey',\n",
       " 'mediocre',\n",
       " 'bride',\n",
       " 'neighborhood',\n",
       " 'christian',\n",
       " 'terribly',\n",
       " 'felt',\n",
       " 'crude',\n",
       " 'thus',\n",
       " 'task',\n",
       " 'professional',\n",
       " 'alas',\n",
       " 'outstanding',\n",
       " 'lesbian',\n",
       " 'rogers',\n",
       " 'beyond',\n",
       " 'wilson',\n",
       " 'torture',\n",
       " 'consequences',\n",
       " 'failure',\n",
       " 'british',\n",
       " 'sons',\n",
       " 'entertaining',\n",
       " 'burt',\n",
       " 'g',\n",
       " 'clothes',\n",
       " '1',\n",
       " 'should',\n",
       " 'anyone',\n",
       " 'roll',\n",
       " 'probably',\n",
       " 'souls',\n",
       " 'title',\n",
       " 'audio',\n",
       " 'path',\n",
       " 'brilliance',\n",
       " 'set',\n",
       " 'enjoy',\n",
       " 'nurse',\n",
       " 'once',\n",
       " 'taylor',\n",
       " 'gritty',\n",
       " 'bbc',\n",
       " 'holy',\n",
       " 'stone',\n",
       " 'greek',\n",
       " 'short',\n",
       " 'driving',\n",
       " 'brando',\n",
       " 'barry',\n",
       " 'arnold',\n",
       " 'buy',\n",
       " 'directors',\n",
       " 'trap',\n",
       " 'horrific',\n",
       " 'reaction',\n",
       " 'fortune',\n",
       " 'holding',\n",
       " 'chan',\n",
       " 'holiday',\n",
       " 'maker',\n",
       " 'hood',\n",
       " 'adam',\n",
       " 'by',\n",
       " 'telling',\n",
       " 'watched',\n",
       " 'game',\n",
       " 'daughter',\n",
       " 'arrive',\n",
       " 'ordinary',\n",
       " 'dancers',\n",
       " 'heads',\n",
       " 'girls',\n",
       " 'first',\n",
       " 'do',\n",
       " 'english',\n",
       " 'built',\n",
       " 'beer',\n",
       " 'blob',\n",
       " 'interviews',\n",
       " 'intensity',\n",
       " 'sick',\n",
       " 'position',\n",
       " 'leader',\n",
       " 'iii',\n",
       " 'horrendous',\n",
       " 'jennifer',\n",
       " 'bo',\n",
       " 'baker',\n",
       " 'decent',\n",
       " 'various',\n",
       " 'worst',\n",
       " 'ha',\n",
       " 'doors',\n",
       " 'television',\n",
       " 'spend',\n",
       " 'loser',\n",
       " 'spoilers',\n",
       " 'birth',\n",
       " 'opportunity',\n",
       " 'chain',\n",
       " 'theaters',\n",
       " 'roger',\n",
       " 'whoever',\n",
       " 'gonna',\n",
       " 'incoherent',\n",
       " 'st',\n",
       " 'courage',\n",
       " 'psychiatrist',\n",
       " 'burning',\n",
       " 'cult',\n",
       " 'deliver',\n",
       " 'soldiers',\n",
       " 'bare',\n",
       " 'murdered',\n",
       " 'improved',\n",
       " 'road',\n",
       " 'concerns',\n",
       " 'returning',\n",
       " 'turns',\n",
       " 'whereas',\n",
       " 'fired',\n",
       " 'middle',\n",
       " 'summary',\n",
       " 'picks',\n",
       " 'radio',\n",
       " 'allow',\n",
       " 'innocent',\n",
       " 'aspects',\n",
       " 'massacre',\n",
       " 'gold',\n",
       " 'while',\n",
       " 'tom',\n",
       " 'jesus',\n",
       " 'violent',\n",
       " 'hunt',\n",
       " 'japan',\n",
       " 'talented',\n",
       " 'looking',\n",
       " 'plastic',\n",
       " 'timing',\n",
       " 'sweet',\n",
       " 'vague',\n",
       " 'minor',\n",
       " 'explains',\n",
       " 'enough',\n",
       " 'standard',\n",
       " 'disgusting',\n",
       " 'douglas',\n",
       " 'ball',\n",
       " 'exercise',\n",
       " \"world's\",\n",
       " 'dislike',\n",
       " 'navy',\n",
       " 'films',\n",
       " 'awful',\n",
       " 'fighting',\n",
       " 'partner',\n",
       " 'a',\n",
       " 'com',\n",
       " 'term',\n",
       " 'store',\n",
       " 'toilet',\n",
       " 'attempting',\n",
       " 'trite',\n",
       " 'finding',\n",
       " 'pilot',\n",
       " 'send',\n",
       " 'clothing',\n",
       " 'touches',\n",
       " 'have',\n",
       " 'itself',\n",
       " 'reactions',\n",
       " 'player',\n",
       " 'natural',\n",
       " 'trust',\n",
       " 'entertained',\n",
       " 'super',\n",
       " 'parker',\n",
       " 'artist',\n",
       " 'age',\n",
       " 'black',\n",
       " 'and',\n",
       " 'word',\n",
       " 'journalist',\n",
       " 'flesh',\n",
       " 'conversation',\n",
       " 'style',\n",
       " 'cinematic',\n",
       " 'stunts',\n",
       " 'below',\n",
       " 'indie',\n",
       " 'used',\n",
       " 'episode',\n",
       " 'easy',\n",
       " 'performance',\n",
       " 'feet',\n",
       " 'victim',\n",
       " 'equally',\n",
       " 'keep',\n",
       " 'oliver',\n",
       " 'profound',\n",
       " 'che',\n",
       " 'hospital',\n",
       " 'exact',\n",
       " 'movement',\n",
       " 'enters',\n",
       " 'around',\n",
       " 'cruel',\n",
       " 'explained',\n",
       " 'semi',\n",
       " 'color',\n",
       " 'considered',\n",
       " 'closer',\n",
       " 'contrast',\n",
       " 'buying',\n",
       " 'friday',\n",
       " 'saying',\n",
       " 'grace',\n",
       " 'jeremy',\n",
       " 'brilliant',\n",
       " 'horrible',\n",
       " 'identity',\n",
       " 'clever',\n",
       " 'opinion',\n",
       " 'alone',\n",
       " 'hundred',\n",
       " 'carries',\n",
       " 'utter',\n",
       " 'whilst',\n",
       " 'buck',\n",
       " 'midnight',\n",
       " 'jimmy',\n",
       " 'stealing',\n",
       " 'part',\n",
       " 'station',\n",
       " 'exist',\n",
       " 'steals',\n",
       " 'woods',\n",
       " 'dangerous',\n",
       " 'protagonists',\n",
       " 'acted',\n",
       " 'equal',\n",
       " 'fish',\n",
       " 'winter',\n",
       " 'individuals',\n",
       " 'scenario',\n",
       " 'j',\n",
       " 'broadway',\n",
       " 'poignant',\n",
       " 'seasons',\n",
       " 'tradition',\n",
       " 'since',\n",
       " 'mature',\n",
       " 'class',\n",
       " 'appealing',\n",
       " \"70's\",\n",
       " 'wonderful',\n",
       " 'culture',\n",
       " 'realize',\n",
       " 'changes',\n",
       " 'reynolds',\n",
       " 'engaged',\n",
       " 'possibly',\n",
       " 'hills',\n",
       " 'bank',\n",
       " 'crying',\n",
       " 'like',\n",
       " 'vs',\n",
       " 'innocence',\n",
       " 'handful',\n",
       " 'energy',\n",
       " 'fights',\n",
       " '000',\n",
       " 'adds',\n",
       " 'peace',\n",
       " 'lisa',\n",
       " 'twist',\n",
       " 'version',\n",
       " 'plain',\n",
       " 'overly',\n",
       " \"50's\",\n",
       " 'useless',\n",
       " 'worlds',\n",
       " 'heston',\n",
       " 'race',\n",
       " 'watches',\n",
       " 'week',\n",
       " 'stands',\n",
       " 'scientific',\n",
       " 'convincing',\n",
       " 'lighting',\n",
       " 'loosely',\n",
       " 'showing',\n",
       " 'worried',\n",
       " 'pacino',\n",
       " 'wind',\n",
       " 'rape',\n",
       " \"would've\",\n",
       " 'tedious',\n",
       " 'bourne',\n",
       " 'caring',\n",
       " 'flawed',\n",
       " 'were',\n",
       " 'alive',\n",
       " 'lord',\n",
       " 'use',\n",
       " 'moon',\n",
       " 'jerk',\n",
       " 'many',\n",
       " 'home',\n",
       " 'what',\n",
       " 'henry',\n",
       " 'partly',\n",
       " 'serial',\n",
       " 'as',\n",
       " 'viewed',\n",
       " 'brown',\n",
       " 'opens',\n",
       " 'beginning',\n",
       " 'incident',\n",
       " 'reminds',\n",
       " 'witness',\n",
       " 'feels',\n",
       " 'pulls',\n",
       " 'separate',\n",
       " 'comic',\n",
       " 'more',\n",
       " 'fan',\n",
       " '14',\n",
       " 'documentaries',\n",
       " 'commercial',\n",
       " \"we'll\",\n",
       " 'argument',\n",
       " 'claire',\n",
       " 'band',\n",
       " 'purpose',\n",
       " 'genuinely',\n",
       " 'asking',\n",
       " 'however',\n",
       " 'clichéd',\n",
       " 'jay',\n",
       " 'notice',\n",
       " 'journey',\n",
       " 'successful',\n",
       " 'center',\n",
       " 'bothered',\n",
       " 'christ',\n",
       " 'involvement',\n",
       " 'glass',\n",
       " 'director',\n",
       " 'tied',\n",
       " 'proof',\n",
       " 'page',\n",
       " 'sole',\n",
       " 'alan',\n",
       " 'allen',\n",
       " 'non',\n",
       " 'advantage',\n",
       " 'eating',\n",
       " 'watching',\n",
       " 'curtis',\n",
       " 'dollars',\n",
       " 'narrator',\n",
       " 'naturally',\n",
       " 'pieces',\n",
       " 'lousy',\n",
       " 'suspense',\n",
       " 'central',\n",
       " 'favourite',\n",
       " 'clear',\n",
       " 'sci',\n",
       " 'air',\n",
       " 'ready',\n",
       " 'glover',\n",
       " 'amount',\n",
       " 'overlooked',\n",
       " 'nice',\n",
       " 'photographer',\n",
       " 'realized',\n",
       " 'create',\n",
       " 'leaving',\n",
       " 'older',\n",
       " 'pure',\n",
       " 'fashion',\n",
       " 'intent',\n",
       " 'con',\n",
       " 'caught',\n",
       " 'virgin',\n",
       " 'why',\n",
       " 'ends',\n",
       " \"that's\",\n",
       " 'green',\n",
       " 'drop',\n",
       " 'tale',\n",
       " 'embarrassing',\n",
       " 'gags',\n",
       " \"couldn't\",\n",
       " 'deeper',\n",
       " 'holmes',\n",
       " 'rented',\n",
       " \"i've\",\n",
       " 'intended',\n",
       " 'twin',\n",
       " 'badly',\n",
       " 'whatsoever',\n",
       " 'hip',\n",
       " 'nazi',\n",
       " 'dogs',\n",
       " 'italy',\n",
       " 'contract',\n",
       " 'stanley',\n",
       " 'editor',\n",
       " 'affair',\n",
       " 'tv',\n",
       " '2003',\n",
       " 'shot',\n",
       " 'across',\n",
       " 'channel',\n",
       " '17',\n",
       " 'follows',\n",
       " 'growing',\n",
       " 'workers',\n",
       " 'eyed',\n",
       " 'dressed',\n",
       " 'frustrated',\n",
       " 'risk',\n",
       " 'coming',\n",
       " 'zombie',\n",
       " 'wins',\n",
       " 'mary',\n",
       " 'laughing',\n",
       " 'mere',\n",
       " 'v',\n",
       " 'emily',\n",
       " 'mst3k',\n",
       " 'offering',\n",
       " 'am',\n",
       " 'homage',\n",
       " 'glad',\n",
       " 'really',\n",
       " 'pregnant',\n",
       " 'oil',\n",
       " 'slightest',\n",
       " 'eve',\n",
       " 'cute',\n",
       " 'freeman',\n",
       " 'countries',\n",
       " 'out',\n",
       " 'created',\n",
       " 'families',\n",
       " \"90's\",\n",
       " 'mood',\n",
       " 'particularly',\n",
       " 'previous',\n",
       " 'evil',\n",
       " 'population',\n",
       " 'weekend',\n",
       " 'garbage',\n",
       " 'winner',\n",
       " 'cox',\n",
       " 'frank',\n",
       " 'full',\n",
       " 'suggests',\n",
       " 'facial',\n",
       " 'interpretation',\n",
       " 'dies',\n",
       " 'arm',\n",
       " 'germany',\n",
       " '80s',\n",
       " 'sold',\n",
       " 'gary',\n",
       " 'africa',\n",
       " 'contained',\n",
       " 'naive',\n",
       " 'crappy',\n",
       " 'repetitive',\n",
       " 'experiences',\n",
       " '25',\n",
       " 'escaped',\n",
       " 'vicious',\n",
       " 'originality',\n",
       " 'work',\n",
       " 'tries',\n",
       " 'eric',\n",
       " 'heavily',\n",
       " 'buried',\n",
       " 'despite',\n",
       " 'nine',\n",
       " 'community',\n",
       " 'maria',\n",
       " 'lincoln',\n",
       " 'base',\n",
       " 'purple',\n",
       " 'miscast',\n",
       " 'ones',\n",
       " 'cartoons',\n",
       " 'speaks',\n",
       " 'constant',\n",
       " 'expert',\n",
       " 'france',\n",
       " 'brutal',\n",
       " 'stereotypes',\n",
       " 'adult',\n",
       " 'idiots',\n",
       " 'sudden',\n",
       " 'standards',\n",
       " 'simon',\n",
       " 'dancing',\n",
       " 'neighbor',\n",
       " 'contain',\n",
       " 'tour',\n",
       " 'finest',\n",
       " 'haunting',\n",
       " 'emotions',\n",
       " 'discovers',\n",
       " 'section',\n",
       " 'doctor',\n",
       " 'confusing',\n",
       " 'anna',\n",
       " 'higher',\n",
       " 'door',\n",
       " 'pace',\n",
       " 'warner',\n",
       " 'fool',\n",
       " 'rare',\n",
       " 'usa',\n",
       " 'triumph',\n",
       " 'care',\n",
       " 'bite',\n",
       " 'told',\n",
       " 'increasingly',\n",
       " 'audiences',\n",
       " 'convoluted',\n",
       " 'topic',\n",
       " 'make',\n",
       " 'unfortunate',\n",
       " 'rated',\n",
       " '7',\n",
       " 'ruth',\n",
       " 'london',\n",
       " 'ray',\n",
       " 'hardy',\n",
       " 'note',\n",
       " 'named',\n",
       " 'honest',\n",
       " 'ward',\n",
       " 'conflict',\n",
       " \"wasn't\",\n",
       " 'larry',\n",
       " 'brian',\n",
       " 'unbelievably',\n",
       " 'grade',\n",
       " 'villain',\n",
       " 'stronger',\n",
       " 'basement',\n",
       " 'underrated',\n",
       " '20',\n",
       " 'confusion',\n",
       " 'model',\n",
       " 'doing',\n",
       " 'effectively',\n",
       " 'whenever',\n",
       " 'devil',\n",
       " 'e',\n",
       " 'odd',\n",
       " 'donald',\n",
       " 'changing',\n",
       " 'stanwyck',\n",
       " 'pleased',\n",
       " 'kill',\n",
       " 'value',\n",
       " 'perhaps',\n",
       " 'pleasant',\n",
       " 'bitter',\n",
       " 'year',\n",
       " 'laughs',\n",
       " 'pushing',\n",
       " 'skills',\n",
       " 'handed',\n",
       " 'dialogue',\n",
       " 'heroine',\n",
       " 'screaming',\n",
       " 'certain',\n",
       " 'huh',\n",
       " 'sorry',\n",
       " 'manner',\n",
       " 'tone',\n",
       " 'broadcast',\n",
       " 'if',\n",
       " 'against',\n",
       " 'writers',\n",
       " 'miserably',\n",
       " 'general',\n",
       " 'segments',\n",
       " 'frequently',\n",
       " 'losing',\n",
       " 'remarkable',\n",
       " 'morning',\n",
       " 'stayed',\n",
       " 'wanted',\n",
       " 'price',\n",
       " 'wwii',\n",
       " 'others',\n",
       " 'mostly',\n",
       " 'strangely',\n",
       " 'understood',\n",
       " 'korean',\n",
       " 'following',\n",
       " 'account',\n",
       " 'accents',\n",
       " 'sort',\n",
       " 'bobby',\n",
       " 'zero',\n",
       " 'dubbed',\n",
       " 'scares',\n",
       " 'settings',\n",
       " 'presentation',\n",
       " 'save',\n",
       " 'bringing',\n",
       " 'albert',\n",
       " 'rule',\n",
       " 'tells',\n",
       " 'inept',\n",
       " 'river',\n",
       " 'indian',\n",
       " 'watchable',\n",
       " 'wondered',\n",
       " 'happened',\n",
       " 'cold',\n",
       " 'think',\n",
       " 'francisco',\n",
       " 'jessica',\n",
       " 'skill',\n",
       " 'meaningful',\n",
       " 'de',\n",
       " 'williams',\n",
       " 'physical',\n",
       " 'front',\n",
       " 'woman',\n",
       " 'direction',\n",
       " 'expectations',\n",
       " 'sharp',\n",
       " 'scripts',\n",
       " 'producers',\n",
       " 'competent',\n",
       " 'bruce',\n",
       " 'paint',\n",
       " 'imdb',\n",
       " 'goal',\n",
       " 'format',\n",
       " 'internet',\n",
       " 'arts',\n",
       " 'ago',\n",
       " '2006',\n",
       " 'surprising',\n",
       " 'rent',\n",
       " 'category',\n",
       " 'person',\n",
       " 'arthur',\n",
       " 'patrick',\n",
       " 'finished',\n",
       " 'north',\n",
       " 'entirely',\n",
       " 'bush',\n",
       " 'will',\n",
       " \"i'm\",\n",
       " 'magic',\n",
       " 'our',\n",
       " 'at',\n",
       " 'days',\n",
       " 'protect',\n",
       " 'chuck',\n",
       " 'drunk',\n",
       " 'synopsis',\n",
       " 'situations',\n",
       " 'millions',\n",
       " 'speak',\n",
       " 'werewolf',\n",
       " 'brooks',\n",
       " 'nevertheless',\n",
       " 'anybody',\n",
       " 'back',\n",
       " 'nude',\n",
       " 'one',\n",
       " 'everyone',\n",
       " 'proved',\n",
       " 'revolution',\n",
       " 'hall',\n",
       " 'horse',\n",
       " 'explore',\n",
       " 'maybe',\n",
       " 'evident',\n",
       " 'kevin',\n",
       " 'include',\n",
       " 'ran',\n",
       " 'east',\n",
       " 'versions',\n",
       " 'superior',\n",
       " 'sloppy',\n",
       " 'raised',\n",
       " 'evening',\n",
       " 'mysterious',\n",
       " 'fit',\n",
       " 'camp',\n",
       " 'premise',\n",
       " 'displays',\n",
       " 'warned',\n",
       " 'complaint',\n",
       " 'revenge',\n",
       " 'zombies',\n",
       " 'thought',\n",
       " 'gag',\n",
       " 'comics',\n",
       " 'secretary',\n",
       " 'aimed',\n",
       " 'building',\n",
       " 'featured',\n",
       " 'ironic',\n",
       " \"they'd\",\n",
       " 'guessing',\n",
       " 'whose',\n",
       " 'elderly',\n",
       " 'makeup',\n",
       " 'laurel',\n",
       " 'tongue',\n",
       " 'tape',\n",
       " 'exactly',\n",
       " 'knowledge',\n",
       " 'religion',\n",
       " 'fact',\n",
       " 'about',\n",
       " 'expected',\n",
       " 'strange',\n",
       " 'ground',\n",
       " 'los',\n",
       " 'university',\n",
       " 'ironically',\n",
       " 'inevitable',\n",
       " 'oh',\n",
       " 'placed',\n",
       " 'edited',\n",
       " 'park',\n",
       " 'point',\n",
       " 'talks',\n",
       " \"hadn't\",\n",
       " 'historical',\n",
       " 'sidney',\n",
       " 'progress',\n",
       " 'occasional',\n",
       " 'experiment',\n",
       " 'faith',\n",
       " 'jail',\n",
       " 'noticed',\n",
       " 'offered',\n",
       " 'fever',\n",
       " 'dave',\n",
       " 'mention',\n",
       " 'false',\n",
       " 'these',\n",
       " 'surprised',\n",
       " 'ann',\n",
       " 'producer',\n",
       " 'danny',\n",
       " 'local',\n",
       " 'moral',\n",
       " \"shouldn't\",\n",
       " 'including',\n",
       " 'number',\n",
       " ...}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:29.156586Z",
     "start_time": "2021-08-01T16:30:29.141627Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGBtwK9Mc6fj",
    "outputId": "597e1c54-63a5-402c-ee96-bdda6bb0ba4c"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = len(word2vec['tiger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:30:41.405582Z",
     "start_time": "2021-08-01T16:30:41.386635Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnqbiMxuVJEu",
    "outputId": "6e2c7b5e-cde2-4abd-df0f-9e0f522cbae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "VOCA_SIZE = 4000 # 어휘 사전의 크기\n",
    "EMBEDDING_SIZE = len(word2vec['tiger'])\n",
    "# EMBEDDING_SIZE = 300 # 단어를 임베딩한 벡터 크기\n",
    "\n",
    "embedding_matrix = np.zeros((VOCA_SIZE, EMBEDDING_SIZE))\n",
    "\n",
    "# tokenizer에 있는 단어 사전을 순회하면서 word2vec의 300차원 vector를 가져옵니다\n",
    "for idx, word in enumerate(word_set):\n",
    "    embedding_vector = word2vec[word] if word in word2vec else None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector\n",
    "        \n",
    "print(embedding_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:43:42.222583Z",
     "start_time": "2021-08-01T16:43:42.201667Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.8433576e-02,  7.6273349e-03, -7.7798814e-02,  8.3519317e-02,\n",
       "        4.3475807e-02, -1.7542869e-02, -1.2871128e-02,  4.0424872e-02,\n",
       "        2.0117095e-02,  1.1593549e-01, -1.5731378e-02,  6.6262470e-03,\n",
       "       -2.6695671e-02, -1.8591628e-03, -1.1059635e-01,  2.2882004e-03,\n",
       "       -7.0171475e-02, -2.8411822e-02, -4.5764007e-02, -7.9133594e-03,\n",
       "        2.7458405e-02,  8.1040431e-04, -4.7909194e-03, -8.0849744e-02,\n",
       "        6.2925513e-03,  4.5001276e-02,  4.1187607e-02,  8.3900683e-02,\n",
       "       -4.7289476e-02,  2.8221138e-02,  3.0890705e-02,  7.3985144e-02,\n",
       "       -7.9324283e-02,  2.7410735e-03,  5.4535445e-02,  2.1261195e-02,\n",
       "       -8.6760931e-03, -4.7289476e-02,  6.2544145e-02, -5.2247241e-02,\n",
       "        1.0144355e-01,  2.7267722e-02, -2.0784486e-02, -6.2162779e-02,\n",
       "       -9.4960317e-02, -3.2606855e-02,  8.6188883e-02,  4.1950341e-02,\n",
       "       -3.4513690e-02, -2.4312129e-03,  1.0068082e-01,  1.5195081e-03,\n",
       "        9.7725224e-03, -1.9831071e-02,  9.7629882e-02,  6.5595075e-02,\n",
       "        3.9280772e-02, -1.4873303e-02,  6.4450979e-02,  2.2214612e-02,\n",
       "       -6.0541970e-03,  4.9196310e-02, -7.7226763e-03,  1.8496286e-02,\n",
       "        5.2628610e-02, -3.0890705e-02, -7.1315579e-02,  3.6801890e-02,\n",
       "        4.4619907e-02, -2.9436746e-03,  1.3943721e-03,  2.4788838e-02,\n",
       "        5.5298176e-02,  7.8561544e-02,  7.1029556e-03, -1.1297990e-02,\n",
       "        2.1833245e-02, -1.5636036e-02, -6.2925513e-03, -3.4323007e-02,\n",
       "        2.4312129e-02, -1.0373175e-01,  8.0087014e-02,  8.9239813e-02,\n",
       "        3.1653438e-02, -5.6823645e-02, -3.4323006e-03,  1.6780137e-01,\n",
       "        4.1711987e-03,  6.6739179e-02,  2.9365238e-02,  2.1928588e-02,\n",
       "        1.3630881e-04,  7.1696945e-02,  6.5595075e-02, -3.6039155e-02,\n",
       "        4.8624258e-02, -9.7629882e-02, -2.5551571e-02,  9.2672117e-02,\n",
       "        3.8375028e-03, -9.1051310e-03,  2.5980608e-03, -5.6442276e-02,\n",
       "        9.5341682e-02, -4.1378289e-02, -2.1451879e-03,  3.5276424e-02,\n",
       "       -2.0403121e-02, -4.5954693e-02,  3.5657790e-02, -1.2775785e-02,\n",
       "       -9.7629882e-02,  1.0427997e-03,  3.3750955e-02, -3.3369590e-02,\n",
       "       -7.1696945e-02,  2.6314305e-02,  5.2628610e-02, -5.3009976e-02,\n",
       "        5.6823645e-02,  6.6357814e-02, -2.5551571e-02, -2.5742255e-02,\n",
       "        5.8635133e-03, -2.2882003e-02,  4.8814941e-02,  3.0318655e-02,\n",
       "        3.2177819e-03, -1.3228658e-03, -1.2585103e-02, -2.5932938e-02,\n",
       "       -1.3645778e-03, -4.7670841e-02, -4.9959041e-02,  8.0563724e-03,\n",
       "       -4.5764007e-02, -2.4026105e-02, -3.6420524e-02,  4.1568972e-02,\n",
       "        1.8972995e-02, -9.3053482e-02, -3.6611207e-02, -3.5657790e-02,\n",
       "        5.4535445e-02,  1.8496286e-02,  4.4047859e-02, -1.5559763e-01,\n",
       "       -7.7036083e-02, -9.1146648e-02,  1.6589453e-02, -4.6336059e-02,\n",
       "        1.9926412e-02,  5.5298176e-02, -6.4450979e-02, -2.9174555e-02,\n",
       "       -1.2356282e-01, -4.3857176e-02, -5.3009976e-02,  2.3168029e-02,\n",
       "       -6.5976448e-02, -1.7542869e-02,  1.7066162e-02,  7.2936388e-03,\n",
       "       -8.3519317e-02,  3.8518041e-02,  3.6039155e-02, -7.8942917e-02,\n",
       "        1.1679356e-02, -6.4832345e-02, -8.4663413e-02,  1.5063986e-02,\n",
       "        8.1993848e-02, -1.0830815e-01, -9.0765283e-02, -1.8972995e-02,\n",
       "        1.0678268e-01,  9.1170485e-04,  6.0065263e-03,  8.6188883e-02,\n",
       "        2.7458405e-02, -3.2225490e-02, -1.6875478e-02, -3.5467107e-02,\n",
       "        8.3519317e-02, -1.1746095e-01, -8.0468379e-02,  3.2988224e-02,\n",
       "       -7.1696945e-02,  1.3919886e-02, -2.5742255e-02,  1.6970819e-02,\n",
       "        6.9027379e-02,  1.4301253e-02, -5.4154076e-02, -4.0615559e-02,\n",
       "       -3.7373941e-02, -8.6760931e-03,  6.5595075e-02, -1.3042742e-01,\n",
       "       -1.0630597e-02,  4.4572237e-03,  3.2797538e-02, -2.5551571e-02,\n",
       "       -4.5191959e-02,  2.6314305e-02, -3.6992572e-02,  2.0307779e-02,\n",
       "       -1.3576655e-01, -2.6886355e-02,  2.8602505e-02,  5.7967745e-02,\n",
       "        5.2628610e-02,  1.0830815e-01,  5.4535445e-02,  1.3042742e-01,\n",
       "        1.0525722e-01,  5.6823645e-02, -5.7586376e-02,  3.2797538e-02,\n",
       "       -3.0509340e-02,  6.5213710e-02, -2.4431306e-03,  7.7036083e-02,\n",
       "        1.6112745e-02, -1.6494112e-02, -1.4720756e-01, -1.0601995e-01,\n",
       "        4.1378289e-02, -4.4429224e-02,  2.8602505e-02, -3.5467107e-02,\n",
       "       -1.9545045e-03,  1.0068082e-01,  1.4396594e-02, -4.2713076e-02,\n",
       "        6.5976448e-02,  4.5525655e-03, -5.8349110e-02, -5.4154076e-02,\n",
       "        5.6060910e-02, -7.0171475e-02, -5.5298176e-02, -8.3423971e-04,\n",
       "        5.3772710e-02,  4.9959041e-02,  3.7564624e-02, -1.2203735e-02,\n",
       "        1.0449448e-01, -4.1759659e-02,  3.4132324e-02,  8.3519317e-02,\n",
       "        3.2988224e-02,  1.4873302e-01, -2.0975171e-02,  2.8221138e-02,\n",
       "       -5.8349110e-02,  2.9436746e-03,  6.4450979e-02,  3.9471459e-02,\n",
       "       -2.3454053e-02, -1.1212182e-01,  1.3576655e-01,  2.5360888e-02,\n",
       "       -2.4598155e-02, -2.7458405e-02, -6.9790110e-02, -2.1749822e-04,\n",
       "        3.9662141e-02, -6.9408745e-02,  4.5382641e-02,  1.7924236e-02,\n",
       "        1.1974915e-01,  4.6717424e-02,  5.8349110e-02,  6.9790110e-02,\n",
       "       -7.4366510e-02,  1.0106218e-02, -9.3053482e-02, -5.9493210e-02,\n",
       "       -3.9852824e-02, -4.5573324e-02,  1.2966469e-01, -4.2522389e-02,\n",
       "        7.7798814e-02, -3.6611207e-02, -6.5213710e-02,  9.7629882e-02,\n",
       "        4.8433576e-02, -5.1103141e-02, -2.1547221e-02,  5.3772710e-02,\n",
       "       -9.3053482e-02,  6.1781410e-02,  7.6654710e-02,  1.2508829e-01,\n",
       "        4.2713076e-02,  1.2156065e-02,  1.2585103e-02,  3.3941638e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['selling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:42:26.348394Z",
     "start_time": "2021-08-01T16:42:26.341413Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.84335758e-02,  7.62733491e-03, -7.77988136e-02,  8.35193172e-02,\n",
       "        4.34758067e-02, -1.75428689e-02, -1.28711276e-02,  4.04248722e-02,\n",
       "        2.01170947e-02,  1.15935490e-01, -1.57313775e-02,  6.62624696e-03,\n",
       "       -2.66956706e-02, -1.85916282e-03, -1.10596351e-01,  2.28820043e-03,\n",
       "       -7.01714754e-02, -2.84118224e-02, -4.57640067e-02, -7.91335944e-03,\n",
       "        2.74584051e-02,  8.10404308e-04, -4.79091937e-03, -8.08497444e-02,\n",
       "        6.29255129e-03,  4.50012758e-02,  4.11876068e-02,  8.39006826e-02,\n",
       "       -4.72894758e-02,  2.82211378e-02,  3.08907051e-02,  7.39851445e-02,\n",
       "       -7.93242827e-02,  2.74107349e-03,  5.45354448e-02,  2.12611947e-02,\n",
       "       -8.67609307e-03, -4.72894758e-02,  6.25441447e-02, -5.22472411e-02,\n",
       "        1.01443551e-01,  2.72677224e-02, -2.07844861e-02, -6.21627793e-02,\n",
       "       -9.49603170e-02, -3.26068550e-02,  8.61888826e-02,  4.19503413e-02,\n",
       "       -3.45136896e-02, -2.43121292e-03,  1.00680821e-01,  1.51950808e-03,\n",
       "        9.77252237e-03, -1.98310707e-02,  9.76298824e-02,  6.55950755e-02,\n",
       "        3.92807722e-02, -1.48733025e-02,  6.44509792e-02,  2.22146120e-02,\n",
       "       -6.05419697e-03,  4.91963103e-02, -7.72267627e-03,  1.84962861e-02,\n",
       "        5.26286103e-02, -3.08907051e-02, -7.13155791e-02,  3.68018895e-02,\n",
       "        4.46199067e-02, -2.94367457e-03,  1.39437208e-03,  2.47888379e-02,\n",
       "        5.52981757e-02,  7.85615444e-02,  7.10295560e-03, -1.12979896e-02,\n",
       "        2.18332447e-02, -1.56360362e-02, -6.29255129e-03, -3.43230069e-02,\n",
       "        2.43121292e-02, -1.03731751e-01,  8.00870135e-02,  8.92398134e-02,\n",
       "        3.16534378e-02, -5.68236448e-02, -3.43230064e-03,  1.67801365e-01,\n",
       "        4.17119870e-03,  6.67391792e-02,  2.93652378e-02,  2.19285879e-02,\n",
       "        1.36308809e-04,  7.16969445e-02,  6.55950755e-02, -3.60391550e-02,\n",
       "        4.86242585e-02, -9.76298824e-02, -2.55515706e-02,  9.26721171e-02,\n",
       "        3.83750279e-03, -9.10513103e-03,  2.59806076e-03, -5.64422756e-02,\n",
       "        9.53416824e-02, -4.13782895e-02, -2.14518793e-03,  3.52764241e-02,\n",
       "       -2.04031207e-02, -4.59546931e-02,  3.56577896e-02, -1.27757853e-02,\n",
       "       -9.76298824e-02,  1.04279967e-03,  3.37509550e-02, -3.33695896e-02,\n",
       "       -7.16969445e-02,  2.63143051e-02,  5.26286103e-02, -5.30099757e-02,\n",
       "        5.68236448e-02,  6.63578138e-02, -2.55515706e-02, -2.57422552e-02,\n",
       "        5.86351333e-03, -2.28820033e-02,  4.88149412e-02,  3.03186551e-02,\n",
       "        3.21778189e-03, -1.32286584e-03, -1.25851026e-02, -2.59329379e-02,\n",
       "       -1.36457779e-03, -4.76708412e-02, -4.99590412e-02,  8.05637240e-03,\n",
       "       -4.57640067e-02, -2.40261052e-02, -3.64205241e-02,  4.15689722e-02,\n",
       "        1.89729948e-02, -9.30534825e-02, -3.66112068e-02, -3.56577896e-02,\n",
       "        5.45354448e-02,  1.84962861e-02,  4.40478586e-02, -1.55597627e-01,\n",
       "       -7.70360827e-02, -9.11466479e-02,  1.65894534e-02, -4.63360585e-02,\n",
       "        1.99264120e-02,  5.52981757e-02, -6.44509792e-02, -2.91745551e-02,\n",
       "       -1.23562820e-01, -4.38571759e-02, -5.30099757e-02,  2.31680293e-02,\n",
       "       -6.59764484e-02, -1.75428689e-02,  1.70661621e-02,  7.29363877e-03,\n",
       "       -8.35193172e-02,  3.85180414e-02,  3.60391550e-02, -7.89429173e-02,\n",
       "        1.16793560e-02, -6.48323447e-02, -8.46634135e-02,  1.50639862e-02,\n",
       "        8.19938481e-02, -1.08308151e-01, -9.07652825e-02, -1.89729948e-02,\n",
       "        1.06782682e-01,  9.11704847e-04,  6.00652630e-03,  8.61888826e-02,\n",
       "        2.74584051e-02, -3.22254896e-02, -1.68754775e-02, -3.54671068e-02,\n",
       "        8.35193172e-02, -1.17460951e-01, -8.04683790e-02,  3.29882242e-02,\n",
       "       -7.16969445e-02,  1.39198862e-02, -2.57422552e-02,  1.69708189e-02,\n",
       "        6.90273792e-02,  1.43012526e-02, -5.41540757e-02, -4.06155586e-02,\n",
       "       -3.73739414e-02, -8.67609307e-03,  6.55950755e-02, -1.30427420e-01,\n",
       "       -1.06305974e-02,  4.45722369e-03,  3.27975377e-02, -2.55515706e-02,\n",
       "       -4.51919585e-02,  2.63143051e-02, -3.69925722e-02,  2.03077793e-02,\n",
       "       -1.35766551e-01, -2.68863551e-02,  2.86025051e-02,  5.79677448e-02,\n",
       "        5.26286103e-02,  1.08308151e-01,  5.45354448e-02,  1.30427420e-01,\n",
       "        1.05257221e-01,  5.68236448e-02, -5.75863756e-02,  3.27975377e-02,\n",
       "       -3.05093396e-02,  6.52137101e-02, -2.44313059e-03,  7.70360827e-02,\n",
       "        1.61127448e-02, -1.64941121e-02, -1.47207558e-01, -1.06019951e-01,\n",
       "        4.13782895e-02, -4.44292240e-02,  2.86025051e-02, -3.54671068e-02,\n",
       "       -1.95450452e-03,  1.00680821e-01,  1.43965939e-02, -4.27130759e-02,\n",
       "        6.59764484e-02,  4.55256552e-03, -5.83491102e-02, -5.41540757e-02,\n",
       "        5.60609102e-02, -7.01714754e-02, -5.52981757e-02, -8.34239705e-04,\n",
       "        5.37727103e-02,  4.99590412e-02,  3.75646241e-02, -1.22037353e-02,\n",
       "        1.04494482e-01, -4.17596586e-02,  3.41323242e-02,  8.35193172e-02,\n",
       "        3.29882242e-02,  1.48733020e-01, -2.09751707e-02,  2.82211378e-02,\n",
       "       -5.83491102e-02,  2.94367457e-03,  6.44509792e-02,  3.94714586e-02,\n",
       "       -2.34540533e-02, -1.12121820e-01,  1.35766551e-01,  2.53608879e-02,\n",
       "       -2.45981552e-02, -2.74584051e-02, -6.97901100e-02, -2.17498222e-04,\n",
       "        3.96621414e-02, -6.94087446e-02,  4.53826413e-02,  1.79242361e-02,\n",
       "        1.19749151e-01,  4.67174239e-02,  5.83491102e-02,  6.97901100e-02,\n",
       "       -7.43665099e-02,  1.01062180e-02, -9.30534825e-02, -5.94932102e-02,\n",
       "       -3.98528241e-02, -4.55733240e-02,  1.29664689e-01, -4.25223894e-02,\n",
       "        7.77988136e-02, -3.66112068e-02, -6.52137101e-02,  9.76298824e-02,\n",
       "        4.84335758e-02, -5.11031412e-02, -2.15472206e-02,  5.37727103e-02,\n",
       "       -9.30534825e-02,  6.17814101e-02,  7.66547099e-02,  1.25088289e-01,\n",
       "        4.27130759e-02,  1.21560646e-02,  1.25851026e-02,  3.39416377e-02])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T16:31:44.482427Z",
     "start_time": "2021-08-01T16:31:44.477470Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04843358,  0.00762733, -0.07779881, ...,  0.01215606,\n",
       "         0.0125851 ,  0.03394164],\n",
       "       [ 0.06131164,  0.05195355, -0.01532791, ..., -0.01936157,\n",
       "        -0.01718339, -0.03081717],\n",
       "       [ 0.11625697,  0.02183507,  0.05547287, ..., -0.01844178,\n",
       "        -0.07170164,  0.04603068],\n",
       "       ...,\n",
       "       [-0.02960569,  0.00631934,  0.01592821, ..., -0.03254895,\n",
       "         0.05644126,  0.00675218],\n",
       "       [-0.077719  , -0.07268166, -0.01029957, ..., -0.09103198,\n",
       "        -0.09031235, -0.0564902 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ValNpKi1Xwzw",
    "outputId": "bb799820-1fa3-4f79-9183-7fd869032186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 400, 300)          1200000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 400, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               186880    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 250)               32250     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,419,381\n",
      "Trainable params: 219,381\n",
      "Non-trainable params: 1,200,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 45s 55ms/step - loss: 0.6701 - accuracy: 0.5843 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.6670 - accuracy: 0.5837 - val_loss: 0.6617 - val_accuracy: 0.5526\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.6499 - accuracy: 0.6216 - val_loss: 0.5999 - val_accuracy: 0.6766\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.6173 - accuracy: 0.6629 - val_loss: 0.6375 - val_accuracy: 0.6354\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.5880 - accuracy: 0.6922 - val_loss: 0.5354 - val_accuracy: 0.7306\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.5982 - accuracy: 0.6673 - val_loss: 0.6280 - val_accuracy: 0.6420\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.5557 - accuracy: 0.7068 - val_loss: 0.5783 - val_accuracy: 0.7160\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.4924 - accuracy: 0.7580 - val_loss: 0.4618 - val_accuracy: 0.7769\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 41s 53ms/step - loss: 0.4636 - accuracy: 0.7754 - val_loss: 0.4503 - val_accuracy: 0.7842\n",
      "Epoch 10/10\n",
      " 39/782 [>.............................] - ETA: 26s - loss: 0.4551 - accuracy: 0.7869"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "# from tensorflow.keras.layers import CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(400))\n",
    "# model.add(Embedding(VOCA_SIZE, EMBEDDING_SIZE))\n",
    "model.add(Embedding(VOCA_SIZE,          \n",
    "                    EMBEDDING_SIZE, \n",
    "                    input_length=400, \n",
    "                    weights=[embedding_matrix], # 숫자로 변환된 word와 embedding_matrix의\n",
    "                    trainable=False             # 인덱스값이 다른데 어떻게 매칭시키는지 의문?\n",
    "                   )\n",
    "         )\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=10, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bwf4ZgPmdObl",
    "outputId": "7a7e8cc6-6781-4c9c-9c07-2456d08fb7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 13s 17ms/step - loss: 0.5450 - accuracy: 0.7220\n",
      "loss = 0.5449949502944946\n",
      "acc = 0.7220399975776672\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_x, test_y)\n",
    "print(\"loss =\", loss)\n",
    "print(\"acc =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzIhPwludp-9"
   },
   "source": [
    "# 보충자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictionary 만들기\n",
    "```\n",
    "딕셔너리1 = dict(key1=value1, key2=value2)\n",
    "딕셔너리2 = dict(zip([key1, key2], [value1, value2]))\n",
    "딕셔너리3 = dict([(key1, value1), (key2, value2)])\n",
    "딕셔너리4 = dict({key1: value1, key2:value2})\n",
    "```\n",
    "---\n",
    "더 일반적인 방법\n",
    "```\n",
    "a = {'Korea': 'Seoul', Canada': 'Ottawa', 'USA': 'Washington D.C'\n",
    "```\n",
    "[출처](https://onnons.tistory.com/159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reverse_word_index.get()\n",
    "Key로 Value얻기(get)\n",
    "```\n",
    ">>> a = {'name':'pey', 'phone':'0119993323', 'birth': '1118'}\n",
    ">>> a.get('name')\n",
    "'pey'\n",
    ">>> a.get('phone')\n",
    "'0119993323'\n",
    "```\n",
    "---\n",
    "```\n",
    ">>> a.get('foo', 'bar')\n",
    "'bar'\n",
    "```\n",
    "a 딕셔너리에는 'foo'에 해당하는 값이 없다. 따라서 디폴트 값인 'bar'를 돌려준다.\n",
    "[출처](https://wikidocs.net/16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 집합 update()\n",
    "```\n",
    ">>> s1 = set([1, 2, 3])\n",
    ">>> s1.update([4, 5, 6])\n",
    ">>> s1\n",
    "{1, 2, 3, 4, 5, 6}\n",
    "```\n",
    "[출처](https://wikidocs.net/1015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rnn_text_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
